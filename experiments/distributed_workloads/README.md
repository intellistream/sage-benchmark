# Distributed CPU-Intensive Workloads for SAGE Benchmark

4ä¸ªé€’è¿›å¼å¤æ‚åº¦çš„åˆ†å¸ƒå¼CPUå¯†é›†å‹å·¥ä½œè´Ÿè½½ï¼Œç”¨äºæµ‹è¯•SAGEçš„åˆ†å¸ƒå¼è°ƒåº¦èƒ½åŠ›å’ŒCPUå¯†é›†å‹è®¡ç®—æ€§èƒ½ã€‚

## ğŸ¯ è®¾è®¡ç›®æ ‡

- **åˆ†å¸ƒå¼ä¼˜å…ˆ**: å……åˆ†åˆ©ç”¨SAGEçš„KeyByã€Joinã€Batchç­‰åˆ†å¸ƒå¼ç®—å­
- **CPUå¯†é›†å‹**: å¢åŠ æ£€ç´¢ã€é‡æ’åºã€èšåˆç­‰CPUæ“ä½œçš„æ•°é‡å’Œå¤æ‚åº¦
- **å‡å°‘LLMä¾èµ–**: ä½¿ç”¨å°æ¨¡å‹ï¼ˆQwen2.5-3Bï¼‰æˆ–é™åˆ¶ç”Ÿæˆé•¿åº¦
- **å¤šé˜¶æ®µå¤„ç†**: é€šè¿‡å¤šä¸ªMapã€Filterã€Joinæ­¥éª¤å¢åŠ pipelineå¤æ‚åº¦

## ğŸ“¦ å·¥ä½œè´Ÿè½½æ¦‚è§ˆ

| Workload   | CPUå ç”¨ | QPS   | ä¸»è¦ç‰¹æ€§                      | å…³é”®ç®—å­                               |
| ---------- | ------- | ----- | ----------------------------- | -------------------------------------- |
| Workload 1 | 30-50%  | 20    | åŸºå‡†RAG Pipeline              | EmbeddingMap, VDBRetrieve              |
| Workload 2 | 50-70%  | 30    | å¤šé˜¶æ®µRAG + ä¸‰è·¯Join          | SessionContext, 3-way Join, RerankMap  |
| Workload 3 | 70-85%  | 25+15 | **åŒæµSemantic Join** + åŒVDB | **Connect+Join(30s)**, Deduplication   |
| Workload 4 | 85-95%  | 40+25 | æè‡´å¤æ‚åº¦ + åŒå±‚Batch        | **Connect+Join(60s)**, DBSCAN, 5ç»´è¯„åˆ† |

**ğŸ”¥ NEW**: Workload 3/4ç°ä½¿ç”¨SAGEæ ‡å‡†åŒæµJoinæ¨¡å¼ï¼ˆ`keyby().connect().join()`ï¼‰

## ğŸ“‹ æ–‡ä»¶ç»“æ„

```
distributed_workloads/
â”œâ”€â”€ __init__.py                 # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ workload_config.py          # ç»Ÿä¸€é…ç½®ç®¡ç†
â”œâ”€â”€ workload_operators.py       # ä¸“ç”¨ç®—å­å®ç°ï¼ˆSource, Map, Sinkï¼‰
â”œâ”€â”€ join_operators.py           # åŒæµJoinç®—å­ï¼ˆNEWï¼‰
â”œâ”€â”€ workload_pipelines.py       # Pipelineæ„å»ºå™¨
â”œâ”€â”€ workload_runner.py          # è¿è¡Œè„šæœ¬
â”œâ”€â”€ test_workload_join.py       # JoinåŠŸèƒ½æµ‹è¯•ï¼ˆNEWï¼‰
â”œâ”€â”€ DUAL_STREAM_JOIN.md         # åŒæµJoinå®ç°è¯´æ˜ï¼ˆNEWï¼‰
â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œå•ä¸ªå·¥ä½œè´Ÿè½½

```bash
# è¿è¡ŒWorkload 1ï¼ˆåŸºå‡†ï¼‰
cd /home/sage/SAGE/packages/sage-benchmark/src/sage/benchmark/benchmark_sage/experiments
python -m distributed_workloads.workload_runner run workload_1

# è¿è¡ŒWorkload 3ï¼ˆåŒæµJoinï¼‰
python -m distributed_workloads.workload_runner run workload_3

# è‡ªå®šä¹‰å‚æ•°
python -m distributed_workloads.workload_runner run workload_1 \
    --qps 30 \
    --num-tasks 500 \
    --parallelism 16 \
    --scheduler load_aware
```

### 2. è¿è¡Œæµ‹è¯•åœºæ™¯

```bash
# è¿è¡Œé¢„å®šä¹‰æµ‹è¯•åœºæ™¯
python -m distributed_workloads.workload_runner scenario scenario_1_baseline
python -m distributed_workloads.workload_runner scenario scenario_3_high
```

### 3. è¿è¡Œæ‰€æœ‰å·¥ä½œè´Ÿè½½

```bash
# ä¾æ¬¡è¿è¡Œæ‰€æœ‰4ä¸ªå·¥ä½œè´Ÿè½½
python -m distributed_workloads.workload_runner all
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç»Ÿä¸€é…ç½®ç±» (`WorkloadConfig`)

æ‰€æœ‰å·¥ä½œè´Ÿè½½ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç±»ï¼Œè‡ªåŠ¨æ ¹æ®workload_nameè®¾ç½®é»˜è®¤å‚æ•°ã€‚

```python
from distributed_workloads import get_config

# è·å–Workload 3çš„é»˜è®¤é…ç½®
config = get_config("workload_3")

# ä¿®æ”¹é…ç½®
config.query_qps = 30.0
config.keyby_parallelism = 16
config.scheduler_type = "load_aware"
```

### å…³é”®é…ç½®é¡¹

| é…ç½®é¡¹              | è¯´æ˜            | Workload 1 | Workload 3 | Workload 4 |
| ------------------- | --------------- | ---------- | ---------- | ---------- |
| `query_qps`         | æŸ¥è¯¢QPS         | 20         | 25         | 40         |
| `doc_qps`           | æ–‡æ¡£QPSï¼ˆåŒæµï¼‰ | -          | 15         | 25         |
| `join_window`       | Joinçª—å£ï¼ˆç§’ï¼‰  | -          | 30.0       | 60.0       |
| `keyby_parallelism` | KeyByå¹¶è¡Œåº¦     | 8          | 8          | 16         |
| `vdb_top_k`         | VDBæ£€ç´¢Top-K    | 15         | 20         | 25         |
| `batch_size`        | æ‰¹é‡å¤§å°        | 8          | 8          | 12         |

## ğŸ“Š ç®—å­è¯´æ˜

### Sourceç®—å­

- **WorkloadQuerySource**: ç»Ÿä¸€æŸ¥è¯¢ç”Ÿæˆæºï¼Œæ”¯æŒQPSæ§åˆ¶ã€æŸ¥è¯¢ç±»å‹æ ‡ç­¾
- **WorkloadDocSource**: æ–‡æ¡£æ›´æ–°æµï¼ˆåŒæµJoinä¸“ç”¨ï¼‰

### Processingç®—å­

- **EmbeddingMapOperator**: Embeddingè®¡ç®—ï¼ˆæ”¯æŒæ‰¹é‡è°ƒç”¨ï¼‰
- **VDBRetrieveOperator**: VDBæ£€ç´¢ï¼ˆSageVDBåç«¯ï¼‰
- **BM25RerankOperator**: BM25é‡æ’åºï¼ˆCPUå¯†é›†: TF-IDFï¼‰
- **SemanticRerankOperator**: è¯­ä¹‰é‡æ’åºï¼ˆEmbeddingç›¸ä¼¼åº¦ï¼‰
- **SemanticJoinOperator**: è¯­ä¹‰Joinï¼ˆCPUå¯†é›†: çª—å£å†…å‘é‡è®¡ç®—ï¼‰
- **DeduplicationOperator**: å»é‡ï¼ˆSimHash + O(nÂ²)ç›¸ä¼¼åº¦çŸ©é˜µ + DBSCANï¼‰

### Sinkç®—å­

- **WorkloadMetricsSink**: æŒ‡æ ‡æ”¶é›†ï¼Œè¾“å‡ºCSVæ ¼å¼ç»“æœ

## ğŸ¨ Pipelineè®¾è®¡

### Workload 1: åŸºå‡†RAG Pipeline

```
QuerySource â†’ EmbeddingMap â†’ KeyBy â†’ VDBRetrieve
    â†’ FilterTopK â†’ Batch â†’ MetricsSink
```

**ç‰¹ç‚¹**: å•æµã€ç®€å•pipelineã€CPUå ç”¨30-50%

### Workload 2: å¤šé˜¶æ®µRAG + ä¸‰è·¯Join

```
QuerySource â†’ SessionContext â†’ KeyBy(user_id) â†’ MemoryRetrieve
    â†’ ContextEnhancement
    â†’ (VDB1 + VDB2 + VDB3)  # ä¸‰è·¯å¹¶è¡Œ
    â†’ Join â†’ FinalRerank â†’ Batch â†’ MetricsSink
```

**ç‰¹ç‚¹**: ä¸‰è·¯å¹¶è¡Œæ£€ç´¢ã€Joinæ±‡èšã€CPUå ç”¨50-70%

### Workload 3: åŒæµSemantic Join + åŒVDB

```
QuerySource â”€â”€â”€â”€â”
                â”œâ†’ SemanticJoin(30s) â†’ KeyBy â†’ MemoryRetrieve
DocSource â”€â”€â”€â”€â”€â”€â”˜        â†’ ContextFusion
                         â†’ (VDB1 + VDB2)
                         â†’ Join â†’ FinalRerank â†’ Deduplication
                         â†’ Batch â†’ MetricsSink
```

**ç‰¹ç‚¹**: åŒæµJoinã€30sçª—å£ã€CPUå ç”¨70-85%

**å…³é”®**: Semantic Joinæ˜¯æœ€å¤§ç“¶é¢ˆï¼ˆ11.5M ops/så‘é‡è®¡ç®—ï¼‰

### Workload 4: æè‡´å¤æ‚åº¦ + åŒå±‚Batch

```
QuerySource â”€â”€â”€â”€â”
                â”œâ†’ SemanticJoin(60s) â†’ KeyBy(16å¹¶è¡Œ)
DocSource â”€â”€â”€â”€â”€â”€â”˜        â†’ GraphMemoryRetrieve
                         â†’ EmbeddingFusion
                         â†’ (VDB1-4stage + VDB2-4stage)
                         â†’ Join â†’ Deduplication(DBSCAN)
                         â†’ FinalRerank(5ç»´åº¦) â†’ DiversityFilter
                         â†’ KeyBy(category) â†’ CategoryAgg
                         â†’ GlobalBatch â†’ MetricsSink
```

**ç‰¹ç‚¹**:

- 60så¤§çª—å£Joinï¼ˆ1500 docsï¼‰
- DBSCANèšç±»å»é‡
- åŒå±‚Batchèšåˆ
- CPUå ç”¨85-95%

**å…³é”®**: Semantic Joinæ˜¯æœ€å¤§ç“¶é¢ˆï¼ˆ61.4M ops/så‘é‡è®¡ç®—ï¼‰

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

### CPUåˆ©ç”¨ç‡

| Workload   | é¢„æœŸCPU | ä¸»è¦ç“¶é¢ˆ                            |
| ---------- | ------- | ----------------------------------- |
| Workload 1 | 30-50%  | VDBæ£€ç´¢                             |
| Workload 2 | 50-70%  | ä¸‰è·¯Join + Rerank                   |
| Workload 3 | 70-85%  | Semantic Join(11.5M ops/s) + å»é‡   |
| Workload 4 | 85-95%  | Semantic Join(61.4M ops/s) + DBSCAN |

### å»¶è¿Ÿé¢„æœŸ

| Workload   | P50    | P95    | P99    |
| ---------- | ------ | ------ | ------ |
| Workload 1 | 200ms  | 400ms  | 600ms  |
| Workload 2 | 500ms  | 1000ms | 1500ms |
| Workload 3 | 800ms  | 1500ms | 2000ms |
| Workload 4 | 1200ms | 2000ms | 3000ms |

## ğŸ” æŒ‡æ ‡æ”¶é›†

æ‰€æœ‰workloadçš„æŒ‡æ ‡è‡ªåŠ¨æ”¶é›†åˆ°CSVæ–‡ä»¶ï¼š

```bash
/tmp/sage_workload_metrics/workload_metrics_<timestamp>.csv
```

CSVæ ¼å¼ï¼š

```csv
task_id,query,total_latency,stage_1_latency,stage_2_latency,
stage_3_latency,stage_4_latency,num_retrieved,num_matched,
dedup_rate,timestamp
```

## ğŸ› ï¸ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°ç®—å­

```python
# åœ¨ workload_operators.py ä¸­æ·»åŠ 
class MyCustomOperator(MapFunction):
    def __init__(self, stage: int = 1, **kwargs):
        super().__init__(**kwargs)
        self.stage_num = stage

    def execute(self, data):
        # ä½ çš„å¤„ç†é€»è¾‘
        data.stage = self.stage_num
        return data
```

### æ·»åŠ æ–°Pipeline

```python
# åœ¨ workload_pipelines.py ä¸­æ·»åŠ 
def build_workload_5(self) -> WorkloadPipelineFactory:
    env = self._create_environment("workload_5")

    (
        env.from_source(WorkloadQuerySource, ...)
        .map(MyCustomOperator, ...)
        .sink(WorkloadMetricsSink, ...)
    )

    return self
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **è®¾è®¡æ–‡æ¡£**: `/home/sage/SAGE/WORKLOAD_DESIGNS.md`
- **SAGEæ¶æ„**: `docs-public/docs_src/dev-notes/package-architecture.md`
- **Operatorå¼€å‘**: `docs-public/docs_src/dev-notes/l4-middleware/operators.md`

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **Semantic Joinä¼˜åŒ–**: Workload 3/4çš„å…³é”®ç“¶é¢ˆï¼Œéœ€ä½¿ç”¨NumPyå‘é‡åŒ–è®¡ç®—
1. **Embeddingæ‰¹é‡**: å»ºè®®batch_size=32-128å‡å°‘ç½‘ç»œå¾€è¿”
1. **å†…å­˜ç®¡ç†**: 60s Joinçª—å£å¯èƒ½å ç”¨1.5MB per window
1. **GPUèµ„æº**: LLMæ¨ç†å’ŒRerankå¯èƒ½ç«äº‰GPUï¼Œå»ºè®®ä½¿ç”¨å°æ¨¡å‹
1. **ç¡¬ä»¶è¦æ±‚**:
   - æœ€ä½: 8èŠ‚ç‚¹ Ã— 8æ ¸ = 64æ ¸
   - æ¨è: 16èŠ‚ç‚¹ Ã— 8æ ¸ = 128æ ¸ï¼ˆWorkload 4ï¼‰

## ğŸ“ å¼•ç”¨

å¦‚æœä½¿ç”¨è¿™äº›workloadè¿›è¡Œè®ºæ–‡å®éªŒï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{sage2025,
  title={SAGE: Stream Analytics for Generative AI Engines},
  author={Your Team},
  journal={Your Conference},
  year={2025}
}
```
