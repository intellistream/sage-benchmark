#!/usr/bin/env python3
"""
Workload 4 Visualization Script

ç”Ÿæˆ Workload 4 åŸºå‡†æµ‹è¯•çš„å¯è§†åŒ–å›¾è¡¨ã€‚

ç”¨æ³•:
    python visualize_workload4.py /tmp/sage_metrics_workload4/
    python visualize_workload4.py /tmp/sage_metrics_workload4/ --output ./report/
"""

import argparse
import sys
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


def load_metrics(metrics_dir: Path) -> pd.DataFrame:
    """åŠ è½½æŒ‡æ ‡ CSV æ–‡ä»¶"""
    metrics_path = metrics_dir / "metrics.csv"
    if not metrics_path.exists():
        print(f"âŒ æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {metrics_path}")
        sys.exit(1)

    df = pd.read_csv(metrics_path)
    print(f"âœ… å·²åŠ è½½ {len(df)} æ¡è®°å½•")
    return df


def plot_latency_distribution(df: pd.DataFrame, output_dir: Path) -> None:
    """ç»˜åˆ¶å»¶è¿Ÿåˆ†å¸ƒç›´æ–¹å›¾"""
    latencies = df["end_to_end_time"] * 1000  # è½¬æ¢ä¸º ms

    plt.figure(figsize=(12, 6))

    # ç›´æ–¹å›¾
    plt.subplot(1, 2, 1)
    plt.hist(latencies, bins=50, color="skyblue", edgecolor="black", alpha=0.7)
    plt.axvline(
        latencies.quantile(0.50),
        color="green",
        linestyle="--",
        label=f"P50: {latencies.quantile(0.50):.1f} ms",
    )
    plt.axvline(
        latencies.quantile(0.95),
        color="orange",
        linestyle="--",
        label=f"P95: {latencies.quantile(0.95):.1f} ms",
    )
    plt.axvline(
        latencies.quantile(0.99),
        color="red",
        linestyle="--",
        label=f"P99: {latencies.quantile(0.99):.1f} ms",
    )
    plt.xlabel("End-to-End Latency (ms)")
    plt.ylabel("Frequency")
    plt.title("Latency Distribution")
    plt.legend()
    plt.grid(alpha=0.3)

    # ç®±çº¿å›¾
    plt.subplot(1, 2, 2)
    plt.boxplot(latencies, vert=True, patch_artist=True)
    plt.ylabel("Latency (ms)")
    plt.title("Latency Box Plot")
    plt.grid(alpha=0.3)

    plt.tight_layout()
    output_path = output_dir / "latency_distribution.png"
    plt.savefig(output_path, dpi=300)
    print(f"âœ… å·²ç”Ÿæˆ: {output_path}")
    plt.close()


def plot_stage_latencies(df: pd.DataFrame, output_dir: Path) -> None:
    """ç»˜åˆ¶å„ Stage å»¶è¿Ÿå¯¹æ¯”"""
    stages = {
        "Semantic Join": (df["join_time"] - df["query_arrival_time"]) * 1000,
        "VDB1": (df["vdb1_end_time"] - df["vdb1_start_time"]) * 1000,
        "VDB2": (df["vdb2_end_time"] - df["vdb2_start_time"]) * 1000,
        "Graph Memory": (df["graph_end_time"] - df["graph_start_time"]) * 1000,
        "Clustering": df["clustering_time"] * 1000,
        "Reranking": df["reranking_time"] * 1000,
        "Batch Wait": df["batch_time"] * 1000,
        "Generation": df["generation_time"] * 1000,
    }

    # è®¡ç®—ç»Ÿè®¡
    stage_names = list(stages.keys())
    p50_values = [stages[name].quantile(0.50) for name in stage_names]
    p95_values = [stages[name].quantile(0.95) for name in stage_names]
    p99_values = [stages[name].quantile(0.99) for name in stage_names]

    plt.figure(figsize=(14, 6))

    # P50/P95/P99 å¯¹æ¯”
    x = np.arange(len(stage_names))
    width = 0.25

    plt.bar(x - width, p50_values, width, label="P50", color="green", alpha=0.8)
    plt.bar(x, p95_values, width, label="P95", color="orange", alpha=0.8)
    plt.bar(x + width, p99_values, width, label="P99", color="red", alpha=0.8)

    plt.xlabel("Stage")
    plt.ylabel("Latency (ms)")
    plt.title("Stage Latency Comparison (P50/P95/P99)")
    plt.xticks(x, stage_names, rotation=45, ha="right")
    plt.legend()
    plt.grid(alpha=0.3, axis="y")
    plt.tight_layout()

    output_path = output_dir / "stage_latencies.png"
    plt.savefig(output_path, dpi=300)
    print(f"âœ… å·²ç”Ÿæˆ: {output_path}")
    plt.close()


def plot_resource_usage(df: pd.DataFrame, output_dir: Path) -> None:
    """ç»˜åˆ¶èµ„æºä½¿ç”¨å›¾"""
    plt.figure(figsize=(14, 5))

    # CPU æ—¶é—´åˆ†å¸ƒ
    plt.subplot(1, 2, 1)
    plt.hist(df["cpu_time"], bins=30, color="lightcoral", edgecolor="black", alpha=0.7)
    plt.axvline(
        df["cpu_time"].mean(),
        color="red",
        linestyle="--",
        label=f"Mean: {df['cpu_time'].mean():.2f} s",
    )
    plt.xlabel("CPU Time (s)")
    plt.ylabel("Frequency")
    plt.title("CPU Time Distribution")
    plt.legend()
    plt.grid(alpha=0.3)

    # å†…å­˜å³°å€¼åˆ†å¸ƒ
    plt.subplot(1, 2, 2)
    plt.hist(df["memory_peak_mb"], bins=30, color="lightgreen", edgecolor="black", alpha=0.7)
    plt.axvline(
        df["memory_peak_mb"].mean(),
        color="green",
        linestyle="--",
        label=f"Mean: {df['memory_peak_mb'].mean():.1f} MB",
    )
    plt.xlabel("Memory Peak (MB)")
    plt.ylabel("Frequency")
    plt.title("Memory Usage Distribution")
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    output_path = output_dir / "resource_usage.png"
    plt.savefig(output_path, dpi=300)
    print(f"âœ… å·²ç”Ÿæˆ: {output_path}")
    plt.close()


def plot_quality_metrics(df: pd.DataFrame, output_dir: Path) -> None:
    """ç»˜åˆ¶è´¨é‡æŒ‡æ ‡"""
    plt.figure(figsize=(14, 10))

    # Join åŒ¹é…æ–‡æ¡£æ•°åˆ†å¸ƒ
    plt.subplot(2, 3, 1)
    plt.hist(df["join_matched_docs"], bins=30, color="skyblue", edgecolor="black", alpha=0.7)
    plt.xlabel("Matched Docs")
    plt.ylabel("Frequency")
    plt.title("Join Matched Docs Distribution")
    plt.grid(alpha=0.3)

    # VDB1 ç»“æœæ•°åˆ†å¸ƒ
    plt.subplot(2, 3, 2)
    plt.hist(df["vdb1_results"], bins=30, color="lightcoral", edgecolor="black", alpha=0.7)
    plt.xlabel("VDB1 Results")
    plt.ylabel("Frequency")
    plt.title("VDB1 Results Distribution")
    plt.grid(alpha=0.3)

    # VDB2 ç»“æœæ•°åˆ†å¸ƒ
    plt.subplot(2, 3, 3)
    plt.hist(df["vdb2_results"], bins=30, color="lightgreen", edgecolor="black", alpha=0.7)
    plt.xlabel("VDB2 Results")
    plt.ylabel("Frequency")
    plt.title("VDB2 Results Distribution")
    plt.grid(alpha=0.3)

    # å›¾éå†èŠ‚ç‚¹æ•°åˆ†å¸ƒ
    plt.subplot(2, 3, 4)
    plt.hist(df["graph_nodes_visited"], bins=30, color="plum", edgecolor="black", alpha=0.7)
    plt.xlabel("Nodes Visited")
    plt.ylabel("Frequency")
    plt.title("Graph Traversal Nodes")
    plt.grid(alpha=0.3)

    # èšç±»æ•°åˆ†å¸ƒ
    plt.subplot(2, 3, 5)
    plt.hist(
        df["clusters_found"],
        bins=range(0, int(df["clusters_found"].max()) + 2),
        color="gold",
        edgecolor="black",
        alpha=0.7,
    )
    plt.xlabel("Clusters")
    plt.ylabel("Frequency")
    plt.title("Clustering Results")
    plt.grid(alpha=0.3)

    # å»é‡æ–‡æ¡£æ•°åˆ†å¸ƒ
    plt.subplot(2, 3, 6)
    plt.hist(df["duplicates_removed"], bins=30, color="salmon", edgecolor="black", alpha=0.7)
    plt.xlabel("Duplicates Removed")
    plt.ylabel("Frequency")
    plt.title("Deduplication Results")
    plt.grid(alpha=0.3)

    plt.tight_layout()
    output_path = output_dir / "quality_metrics.png"
    plt.savefig(output_path, dpi=300)
    print(f"âœ… å·²ç”Ÿæˆ: {output_path}")
    plt.close()


def plot_latency_waterfall(df: pd.DataFrame, output_dir: Path) -> None:
    """ç»˜åˆ¶å»¶è¿Ÿç€‘å¸ƒå›¾ï¼ˆå †å å›¾ï¼‰"""
    # è®¡ç®—å„ stage çš„å¹³å‡å»¶è¿Ÿ
    stages = {
        "Query Embedding": (df["query_embedding_time"]) * 1000,
        "Doc Embedding": (df["doc_embedding_time"]) * 1000,
        "Semantic Join": (df["join_time"] - df["query_arrival_time"]) * 1000,
        "Graph Memory": (df["graph_end_time"] - df["graph_start_time"]) * 1000,
        "VDB1": (df["vdb1_end_time"] - df["vdb1_start_time"]) * 1000,
        "VDB2": (df["vdb2_end_time"] - df["vdb2_start_time"]) * 1000,
        "Aggregation": 15,  # ä¼°ç®—
        "Clustering": df["clustering_time"] * 1000,
        "Reranking": df["reranking_time"] * 1000,
        "MMR": 10,  # ä¼°ç®—
        "Batch Wait": df["batch_time"] * 1000,
        "Generation": df["generation_time"] * 1000,
    }

    stage_names = list(stages.keys())
    stage_means = [
        stages[name].mean() if hasattr(stages[name], "mean") else stages[name]
        for name in stage_names
    ]

    # å †å æŸ±çŠ¶å›¾
    plt.figure(figsize=(14, 6))
    colors = plt.cm.Set3(np.linspace(0, 1, len(stage_names)))

    bottom = 0
    for i, (name, mean) in enumerate(zip(stage_names, stage_means)):
        plt.barh(0, mean, left=bottom, height=0.5, color=colors[i], label=name, edgecolor="black")
        # æ·»åŠ æ ‡ç­¾
        if mean > 20:  # åªæ˜¾ç¤ºè¶…è¿‡ 20ms çš„æ ‡ç­¾
            plt.text(
                bottom + mean / 2,
                0,
                f"{mean:.0f}ms",
                ha="center",
                va="center",
                fontsize=9,
                fontweight="bold",
            )
        bottom += mean

    plt.xlabel("Latency (ms)")
    plt.title(f"Latency Waterfall (Total: {bottom:.1f} ms)")
    plt.yticks([])
    plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
    plt.grid(alpha=0.3, axis="x")
    plt.tight_layout()

    output_path = output_dir / "latency_waterfall.png"
    plt.savefig(output_path, dpi=300)
    print(f"âœ… å·²ç”Ÿæˆ: {output_path}")
    plt.close()


def main():
    parser = argparse.ArgumentParser(description="Visualize Workload 4 metrics")
    parser.add_argument("metrics_dir", type=Path, help="Directory containing metrics.csv")
    parser.add_argument(
        "--output", type=Path, help="Output directory for plots (default: metrics_dir)"
    )

    args = parser.parse_args()

    # ç¡®å®šè¾“å‡ºç›®å½•
    output_dir = args.output if args.output else args.metrics_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æ•°æ®
    df = load_metrics(args.metrics_dir)

    # ç”Ÿæˆå›¾è¡¨
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    plot_latency_distribution(df, output_dir)
    plot_stage_latencies(df, output_dir)
    plot_resource_usage(df, output_dir)
    plot_quality_metrics(df, output_dir)
    plot_latency_waterfall(df, output_dir)

    print(f"\nâœ… æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")


if __name__ == "__main__":
    main()
