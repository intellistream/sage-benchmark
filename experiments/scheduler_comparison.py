#!/usr/bin/env python3
"""
è°ƒåº¦å™¨å¯¹æ¯”ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„è°ƒåº¦ç­–ç•¥å¹¶å¯¹æ¯”æ€§èƒ½æŒ‡æ ‡

æ”¯æŒé€šè¿‡ --backend é€‰æ‹©è¿è¡Œåç«¯ï¼ˆé»˜è®¤ sageï¼‰ï¼Œä¿æŒå·¥ä½œè´Ÿè½½é€»è¾‘åç«¯æ— å…³ã€‚

ä½¿ç”¨ç¤ºä¾‹::

    python experiments/scheduler_comparison.py
    python experiments/scheduler_comparison.py --backend sage --scheduler fifo --items 10

@test:timeout=90
@test:category=scheduler
"""

import argparse
import time

from sage.common.core import MapFunction, SinkFunction, SourceFunction
from sage.kernel.api import FlownetEnvironment
from sage.kernel.api.local_environment import LocalEnvironment
from sage.kernel.scheduler.impl import FIFOScheduler, LoadAwareScheduler

from common.execution_guard import run_pipeline_bounded

# Register available backends (import triggers @register_runner decoration)
# Use direct 'backends.*' imports â€“ experiments/ is in sys.path when this
# script is executed directly (Python adds the script's directory).
import backends.sage_runner  # noqa: F401  registers "sage"
from backends.base import WorkloadSpec, get_runner, list_backends


class DataSource(SourceFunction):
    """ç®€å•çš„æ•°æ®æºï¼Œç”Ÿæˆä¸€æ‰¹æµ‹è¯•æ•°æ®"""

    def __init__(self, total_items=20, **kwargs):
        super().__init__(**kwargs)
        self.total_items = total_items
        self.current = 0

    def execute(self, data=None):
        if self.current >= self.total_items:
            return None

        data = f"data_{self.current}"
        self.current += 1
        print(f"ğŸ“¤ Source: {data}")
        return data


class HeavyProcessor(MapFunction):
    """æ¨¡æ‹Ÿèµ„æºå¯†é›†å‹å¤„ç†"""

    def execute(self, data):
        # æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—ï¼ˆå‡å°‘åˆ°0.01ç§’ä»¥åŠ å¿«æµ‹è¯•ï¼‰
        time.sleep(0.01)
        result = f"processed_{data}"
        print(f"âš™ï¸  HeavyProcessor: {data} -> {result}")
        return result


class LightFilter(MapFunction):
    """æ¨¡æ‹Ÿè½»é‡çº§è¿‡æ»¤"""

    def execute(self, data):
        # åªä¿ç•™å¶æ•°ç¼–å·çš„æ•°æ®
        item_id = int(data.split("_")[-1])
        if item_id % 2 == 0:
            print(f"âœ… LightFilter: {data} passed")
            return data
        else:
            print(f"âŒ LightFilter: {data} filtered")
            return None


class ResultSink(SinkFunction):
    """æ”¶é›†ç»“æœ"""

    _all_results: list[str] = []

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.results = []

    def execute(self, data):
        if data:
            self.results.append(data)
            ResultSink._all_results.append(data)
            print(f"ğŸ’¾ Sink: {data}")

    @classmethod
    def clear_all_results(cls):
        cls._all_results.clear()

    @classmethod
    def result_count(cls) -> int:
        return len(cls._all_results)


def run_with_scheduler(scheduler, env_class, scheduler_name):
    """ä½¿ç”¨æŒ‡å®šè°ƒåº¦å™¨è¿è¡Œ pipeline"""
    print(f"\n{'=' * 60}")
    print(f"ğŸš€ è¿è¡Œå®éªŒ: {scheduler_name}")
    print(f"{'=' * 60}\n")

    env = None
    try:
        ResultSink.clear_all_results()

        # åˆ›å»ºç¯å¢ƒå¹¶æŒ‡å®šè°ƒåº¦å™¨
        if env_class == LocalEnvironment:
            env = LocalEnvironment(name=f"scheduler_test_{scheduler_name}", scheduler=scheduler)
        else:
            env = FlownetEnvironment(name=f"scheduler_test_{scheduler_name}", scheduler=scheduler)

        # æ„å»º pipeline
        # æ³¨æ„ï¼šå¹¶è¡Œåº¦åœ¨ operator çº§åˆ«æŒ‡å®š
        (
            env.from_source(DataSource, total_items=10)  # å‡å°‘åˆ°10ä¸ªé¡¹ç›®ä»¥åŠ å¿«æµ‹è¯•
            .map(HeavyProcessor, parallelism=2)  # èµ„æºå¯†é›†å‹ operatorï¼Œ2 ä¸ªå¹¶è¡Œå®ä¾‹
            .filter(LightFilter, parallelism=1)  # è½»é‡çº§ operatorï¼Œ1 ä¸ªå¹¶è¡Œå®ä¾‹
            .sink(ResultSink)  # type: ignore[arg-type]  # Pass class, not instance
        )

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        # æäº¤æ‰§è¡Œ
        print(f"â–¶ï¸  å¼€å§‹æ‰§è¡Œ pipeline (è°ƒåº¦å™¨: {scheduler_name})...\n")

        # ä½¿ç”¨å—æ§è¶…æ—¶ï¼Œé¿å…æ‰§è¡Œå¡ä½
        max_wait_time = 30  # æœ€å¤§ç­‰å¾…30ç§’
        try:
            guard_result = run_pipeline_bounded(
                env,
                timeout_seconds=max_wait_time,
                poll_interval_seconds=0.2,
            )

            if guard_result.timed_out:
                print(f"âš ï¸  {scheduler_name} æ‰§è¡Œè¶…æ—¶ ({max_wait_time}s)ï¼Œå·²åœæ­¢ä»»åŠ¡")

        except Exception as e:
            print(f"âŒ {scheduler_name} æ‰§è¡Œå‡ºé”™: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è®°å½•é”™è¯¯å¹¶ç»§ç»­

        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        elapsed = end_time - start_time

        # è·å–è°ƒåº¦å™¨æŒ‡æ ‡
        try:
            metrics = {}
            if (
                hasattr(env, "scheduler")
                and env.scheduler is not None
                and hasattr(env.scheduler, "get_metrics")
            ):
                metrics = env.scheduler.get_metrics()  # type: ignore[union-attr]
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å–è°ƒåº¦å™¨æŒ‡æ ‡: {e}")
            metrics = {"error": str(e)}

        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š {scheduler_name} æ‰§è¡Œç»“æœ")
        print(f"{'=' * 60}")
        print(f"æ€»è€—æ—¶: {elapsed:.2f} ç§’")
        print(f"å¤„ç†ç»“æœæ•°: {ResultSink.result_count()}")
        print("è°ƒåº¦å™¨æŒ‡æ ‡:")
        for key, value in metrics.items():
            print(f"  - {key}: {value}")
        print(f"{'=' * 60}\n")

        return {
            "scheduler": scheduler_name,
            "elapsed_time": elapsed,
            "metrics": metrics,
            "results_count": ResultSink.result_count(),
        }

    except Exception as e:
        print(f"âŒ {scheduler_name} è¿è¡Œå¤±è´¥: {e}")
        return {
            "scheduler": scheduler_name,
            "elapsed_time": 0,
            "metrics": {"error": str(e)},
            "results_count": 0,
        }
    finally:
        # ç¡®ä¿èµ„æºæ¸…ç†
        if env:
            try:
                if hasattr(env, "close"):
                    env.close()
                elif hasattr(env, "shutdown"):
                    env.shutdown()  # type: ignore[union-attr]
            except Exception:  # noqa: S110
                pass


def main():
    """ä¸»å‡½æ•°ï¼šå¯¹æ¯”ä¸åŒè°ƒåº¦ç­–ç•¥ï¼ˆæ”¯æŒ --backend é€‰æ‹©è¿è¡Œåç«¯ï¼‰"""

    # ------------------------------------------------------------------
    # CLI argument parsing
    # ------------------------------------------------------------------
    parser = argparse.ArgumentParser(
        description="SAGE è°ƒåº¦å™¨å¯¹æ¯”ç¤ºä¾‹ â€“ æ”¯æŒå¤šåç«¯è¿è¡Œ",
    )
    parser.add_argument(
        "--backend",
        default="sage",
        choices=list_backends() or ["sage"],
        help="é€‰æ‹©è¿è¡Œåç«¯ï¼ˆé»˜è®¤: sageï¼‰",
    )
    parser.add_argument(
        "--scheduler",
        default="fifo",
        choices=["fifo", "load_aware", "default"],
        help="è°ƒåº¦ç­–ç•¥ï¼ˆé»˜è®¤: fifoï¼‰",
    )
    parser.add_argument(
        "--items",
        type=int,
        default=10,
        help="æ•°æ®æºäº§ç”Ÿçš„ item æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰",
    )
    parser.add_argument(
        "--parallelism",
        type=int,
        default=2,
        help="å¤„ç†ç®—å­çš„å¹¶è¡Œåº¦ï¼ˆé»˜è®¤: 2ï¼‰",
    )
    args = parser.parse_args()

    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           SAGE è°ƒåº¦å™¨å¯¹æ¯”ç¤ºä¾‹                                  â•‘
â•‘  æ¼”ç¤ºå¦‚ä½•åœ¨ Environment çº§åˆ«é…ç½®ä¸åŒçš„è°ƒåº¦ç­–ç•¥                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    )

    # ------------------------------------------------------------------
    # Backend-abstraction path (new)
    # Runs the workload through the selected backend via WorkloadRunner.
    # ------------------------------------------------------------------
    import os

    test_mode = (
        os.environ.get("SAGE_EXAMPLES_MODE") == "test"
        or os.environ.get("SAGE_TEST_MODE") == "true"
    )

    spec = WorkloadSpec(
        name="scheduler_demo",
        total_items=args.items,
        parallelism=args.parallelism,
        scheduler_name=args.scheduler,
    )

    print(f"\nğŸ”§ åç«¯: {args.backend} | è°ƒåº¦å™¨: {args.scheduler} | items: {args.items}")
    print(f"   å¯ç”¨åç«¯: {', '.join(list_backends())}\n")

    runner = get_runner(args.backend)
    result = runner.run(spec)

    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š è¿è¡Œç»“æœ ({args.backend})")
    print(f"{'=' * 60}")
    print(result.summary())
    print(f"{'=' * 60}\n")

    results = [result]

    # ------------------------------------------------------------------
    # Legacy multi-scheduler comparison (SAGE default path, unchanged)
    # Only runs in non-test mode to keep CI fast.
    # ------------------------------------------------------------------
    if not test_mode and args.backend == "sage":
        time.sleep(1)
        print("\nğŸ§ª å®éªŒ 2: è´Ÿè½½æ„ŸçŸ¥è°ƒåº¦å™¨ (Local) â€“ å¯¹æ¯”ç»„")
        result2 = run_with_scheduler(
            scheduler=LoadAwareScheduler(max_concurrent=10),
            env_class=LocalEnvironment,
            scheduler_name="LoadAware_Local",
        )
        results.append(result2)

    # ------------------------------------------------------------------
    # Summary
    # ------------------------------------------------------------------
    print("\n" + "=" * 80)
    print("ğŸ“ˆ è°ƒåº¦å™¨æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("=" * 80)

    for r in results:
        if hasattr(r, "summary"):
            # RunResult (new abstraction)
            print(f"\n[{r.backend}/{r.scheduler_name}]")
            print(r.summary())
        else:
            # legacy dict from run_with_scheduler
            print(f"\n{r['scheduler']}:")
            print(f"  æ€»è€—æ—¶: {r['elapsed_time']:.2f} ç§’")
            print(f"  è°ƒåº¦ç­–ç•¥: {r['metrics'].get('scheduler_type', 'N/A')}")
            print(f"  å·²è°ƒåº¦ä»»åŠ¡æ•°: {r['metrics'].get('total_scheduled', 'N/A')}")
            if "avg_latency_ms" in r["metrics"]:
                print(f"  å¹³å‡å»¶è¿Ÿ: {r['metrics']['avg_latency_ms']:.2f} ms")

    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print("=" * 80)

    print(
        """
ğŸ’¡ å…³é”®è¦ç‚¹ï¼š
  1. é€šè¿‡ --backend é€‰æ‹©è¿è¡Œåç«¯ï¼Œå·¥ä½œè´Ÿè½½é€»è¾‘æ— éœ€ä¿®æ”¹
     - python scheduler_comparison.py --backend sage
     - python scheduler_comparison.py --backend ray   (éœ€å®‰è£… ray_runner)

  2. ç”¨æˆ·åœ¨åˆ›å»º Environment æ—¶æŒ‡å®šè°ƒåº¦ç­–ç•¥
     - env = LocalEnvironment(scheduler="fifo")
     - env = FlownetEnvironment(scheduler=LoadAwareScheduler())

  3. å¹¶è¡Œåº¦åœ¨å®šä¹‰ transformation æ—¶æŒ‡å®š
     - .map(HeavyProcessor, parallelism=4)
     - .filter(LightFilter, parallelism=2)
    """
    )


if __name__ == "__main__":
    main()
