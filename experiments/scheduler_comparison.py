#!/usr/bin/env python3
"""
è°ƒåº¦å™¨å¯¹æ¯”ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„è°ƒåº¦ç­–ç•¥å¹¶å¯¹æ¯”æ€§èƒ½æŒ‡æ ‡

æ”¯æŒé€šè¿‡ --backend é€‰æ‹©è¿è¡Œåç«¯ï¼ˆé»˜è®¤ sageï¼‰ï¼Œä¿æŒå·¥ä½œè´Ÿè½½é€»è¾‘åç«¯æ— å…³ã€‚

ä½¿ç”¨ç¤ºä¾‹::

    python experiments/scheduler_comparison.py
    python experiments/scheduler_comparison.py --backend sage --scheduler fifo --items 10

@test:timeout=90
@test:category=scheduler
"""

import argparse
import sys
import time
import uuid
from importlib import metadata
from pathlib import Path

# ---------------------------------------------------------------------------
# sys.path guard â€“ make experiments/ importable regardless of CWD.
# Python adds the script's parent directory only when executed directly.
# When the file is discovered via pytest / tox from the repo root, the
# experiments/ package root is absent from sys.path, which causes
#   ModuleNotFoundError: No module named 'backends'
# preventing backend registration and producing "Unknown backend" errors.
# ---------------------------------------------------------------------------
_EXPERIMENTS_DIR = Path(__file__).resolve().parent
if str(_EXPERIMENTS_DIR) not in sys.path:
    sys.path.insert(0, str(_EXPERIMENTS_DIR))

# Register available backends (import triggers @register_runner decoration)
import backends.sage_runner  # noqa: F401  registers "sage"
from backends.base import WorkloadSpec, get_runner, list_backends
from common.component_versions import collect_component_versions
from common.metrics_schema import (
    UnifiedMetricsRecord,
    compute_backend_hash,
    compute_config_hash,
)
from common.result_writer import append_jsonl_record, export_jsonl_to_csv
from common.system_profile import collect_system_profile
from sage.common.core import MapFunction, SinkFunction, SourceFunction

try:
    from _version import __version__ as BENCHMARK_VERSION
except Exception:
    BENCHMARK_VERSION = "unknown"

try:
    SAGE_VERSION = metadata.version("isage")
except Exception:
    SAGE_VERSION = "unknown"

try:
    SAGELLM_VERSION = metadata.version("isagellm")
except Exception:
    SAGELLM_VERSION = "unknown"


class DataSource(SourceFunction):
    """ç®€å•çš„æ•°æ®æºï¼Œç”Ÿæˆä¸€æ‰¹æµ‹è¯•æ•°æ®"""

    def __init__(self, total_items=20, **kwargs):
        super().__init__(**kwargs)
        self.total_items = total_items
        self.current = 0

    def execute(self, data=None):
        if self.current >= self.total_items:
            return None

        data = f"data_{self.current}"
        self.current += 1
        print(f"ğŸ“¤ Source: {data}")
        return data


class HeavyProcessor(MapFunction):
    """æ¨¡æ‹Ÿèµ„æºå¯†é›†å‹å¤„ç†"""

    def execute(self, data):
        # æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—ï¼ˆå‡å°‘åˆ°0.01ç§’ä»¥åŠ å¿«æµ‹è¯•ï¼‰
        time.sleep(0.01)
        result = f"processed_{data}"
        print(f"âš™ï¸  HeavyProcessor: {data} -> {result}")
        return result


class LightFilter(MapFunction):
    """æ¨¡æ‹Ÿè½»é‡çº§è¿‡æ»¤"""

    def execute(self, data):
        # åªä¿ç•™å¶æ•°ç¼–å·çš„æ•°æ®
        item_id = int(data.split("_")[-1])
        if item_id % 2 == 0:
            print(f"âœ… LightFilter: {data} passed")
            return data
        else:
            print(f"âŒ LightFilter: {data} filtered")
            return None


class ResultSink(SinkFunction):
    """æ”¶é›†ç»“æœ"""

    _all_results: list[str] = []

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.results = []

    def execute(self, data):
        if data:
            self.results.append(data)
            ResultSink._all_results.append(data)
            print(f"ğŸ’¾ Sink: {data}")

    @classmethod
    def clear_all_results(cls):
        cls._all_results.clear()

    @classmethod
    def result_count(cls) -> int:
        return len(cls._all_results)


def build_unified_record(
    *,
    backend: str,
    scheduler_name: str,
    elapsed_time: float,
    results_count: int,
    raw_metrics: dict,
    workload: str,
    run_id: str,
    seed: int,
    nodes: int,
    parallelism: int,
    config_payload: dict,
) -> UnifiedMetricsRecord:
    """Build a unified metrics record from backend run output."""
    throughput = results_count / elapsed_time if elapsed_time > 0 else None
    return UnifiedMetricsRecord(
        backend=backend,
        workload=workload,
        run_id=run_id,
        seed=seed,
        nodes=nodes,
        parallelism=parallelism,
        throughput=throughput,
        latency_p50=raw_metrics.get("latency_p50"),
        latency_p95=raw_metrics.get("latency_p95"),
        latency_p99=raw_metrics.get("latency_p99"),
        success_rate=raw_metrics.get("success_rate"),
        duration_seconds=elapsed_time,
        config_hash=compute_config_hash(config_payload),
        backend_hash=compute_backend_hash(backend),
        metadata={
            "scheduler_name": scheduler_name,
            "sage_version": SAGE_VERSION,
            "sagellm_version": SAGELLM_VERSION,
            "benchmark_version": BENCHMARK_VERSION,
            "model_name": "unknown",
            "embedding_model_name": "unknown",
            "system_profile": collect_system_profile(),
            "component_versions": collect_component_versions(),
            "results_count": results_count,
            "raw_metrics": raw_metrics,
        },
    )


def main():
    """ä¸»å‡½æ•°ï¼šå¯¹æ¯”ä¸åŒè°ƒåº¦ç­–ç•¥ï¼ˆæ”¯æŒ --backend é€‰æ‹©è¿è¡Œåç«¯ï¼‰"""

    # ------------------------------------------------------------------
    # CLI argument parsing
    # ------------------------------------------------------------------
    parser = argparse.ArgumentParser(
        description="SAGE è°ƒåº¦å™¨å¯¹æ¯”ç¤ºä¾‹ â€“ æ”¯æŒå¤šåç«¯è¿è¡Œ",
    )
    parser.add_argument(
        "--backend",
        default="sage",
        choices=list_backends() or ["sage"],
        help="é€‰æ‹©è¿è¡Œåç«¯ï¼ˆé»˜è®¤: sageï¼‰",
    )
    parser.add_argument(
        "--scheduler",
        default="fifo",
        choices=["fifo", "load_aware", "default"],
        help="è°ƒåº¦ç­–ç•¥ï¼ˆé»˜è®¤: fifoï¼‰",
    )
    parser.add_argument(
        "--items",
        type=int,
        default=10,
        help="æ•°æ®æºäº§ç”Ÿçš„ item æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰",
    )
    parser.add_argument(
        "--parallelism",
        type=int,
        default=2,
        help="å¤„ç†ç®—å­çš„å¹¶è¡Œåº¦ï¼ˆé»˜è®¤: 2ï¼‰",
    )
    parser.add_argument(
        "--nodes",
        type=int,
        default=1,
        help="ç”¨äºè®°å½•å¯¹æ¯”å…ƒæ•°æ®çš„èŠ‚ç‚¹æ•°ï¼ˆé»˜è®¤: 1ï¼‰",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="ç”¨äºè®°å½•å¯¹æ¯”å…ƒæ•°æ®çš„éšæœºç§å­ï¼ˆé»˜è®¤: 42ï¼‰",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="results/scheduler_comparison",
        help="ç»Ÿä¸€ç»“æœè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: results/scheduler_comparisonï¼‰",
    )
    parser.add_argument(
        "--run-id",
        type=str,
        default="",
        help="å¯é€‰è¿è¡Œ IDï¼›ä¸ºç©ºæ—¶è‡ªåŠ¨ç”Ÿæˆã€‚",
    )
    parser.add_argument(
        "--workload",
        type=str,
        default="scheduler_comparison",
        help="å·¥ä½œè´Ÿè½½æ ‡è¯†ï¼ˆé»˜è®¤: scheduler_comparisonï¼‰ã€‚",
    )
    args = parser.parse_args()

    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           SAGE è°ƒåº¦å™¨å¯¹æ¯”ç¤ºä¾‹                                  â•‘
â•‘  æ¼”ç¤ºå¦‚ä½•åœ¨ Environment çº§åˆ«é…ç½®ä¸åŒçš„è°ƒåº¦ç­–ç•¥                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    )

    # ------------------------------------------------------------------
    # Backend-abstraction path (new)
    # Runs the workload through the selected backend via WorkloadRunner.
    # ------------------------------------------------------------------
    import os

    test_mode = (
        os.environ.get("SAGE_EXAMPLES_MODE") == "test" or os.environ.get("SAGE_TEST_MODE") == "true"
    )

    spec = WorkloadSpec(
        name="scheduler_demo",
        total_items=args.items,
        parallelism=args.parallelism,
        scheduler_name=args.scheduler,
    )

    print(f"\nğŸ”§ åç«¯: {args.backend} | è°ƒåº¦å™¨: {args.scheduler} | items: {args.items}")
    print(f"   å¯ç”¨åç«¯: {', '.join(list_backends())}\n")

    runner = get_runner(args.backend)
    result = runner.run(spec)

    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š è¿è¡Œç»“æœ ({args.backend})")
    print(f"{'=' * 60}")
    print(result.summary())
    print(f"{'=' * 60}\n")

    config_payload = {
        "backend": args.backend,
        "scheduler": args.scheduler,
        "items": args.items,
        "parallelism": args.parallelism,
        "nodes": args.nodes,
        "seed": args.seed,
        "workload": args.workload,
    }
    run_id = args.run_id.strip() or f"{args.backend}-{uuid.uuid4().hex[:12]}"
    unified_record = build_unified_record(
        backend=result.backend,
        scheduler_name=result.scheduler_name,
        elapsed_time=result.elapsed_time,
        results_count=result.results_count,
        raw_metrics=result.metrics,
        workload=args.workload,
        run_id=run_id,
        seed=args.seed,
        nodes=args.nodes,
        parallelism=args.parallelism,
        config_payload=config_payload,
    )

    output_dir = Path(args.output_dir)
    jsonl_path = output_dir / "unified_results.jsonl"
    csv_path = output_dir / "unified_results.csv"
    append_jsonl_record(jsonl_path, unified_record.to_dict())
    export_jsonl_to_csv(jsonl_path, csv_path)
    print(f"ğŸ“¦ Unified JSONL: {jsonl_path}")
    print(f"ğŸ“¦ Unified CSV:   {csv_path}\n")

    results = [result]

    # ------------------------------------------------------------------
    # Multi-scheduler comparison: complementary scheduler via the same
    # WorkloadRunner abstraction â€“ no new daemon is spawned, no port fight.
    # Skipped when the user already chose load_aware, or in test mode.
    # ------------------------------------------------------------------
    if not test_mode and args.backend == "sage" and args.scheduler != "load_aware":
        time.sleep(0.5)
        print("\nğŸ§ª å®éªŒ 2: è´Ÿè½½æ„ŸçŸ¥è°ƒåº¦å™¨ â€“ å¯¹æ¯”ç»„")
        spec2 = WorkloadSpec(
            name="scheduler_demo_load_aware",
            total_items=args.items,
            parallelism=args.parallelism,
            scheduler_name="load_aware",
        )
        result2 = runner.run(spec2)
        results.append(result2)

    # ------------------------------------------------------------------
    # Summary
    # ------------------------------------------------------------------
    print("\n" + "=" * 80)
    print("ğŸ“ˆ è°ƒåº¦å™¨æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("=" * 80)

    for r in results:
        print(f"\n[{r.backend}/{r.scheduler_name}]")
        print(r.summary())

    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print("=" * 80)

    print(
        """
ğŸ’¡ å…³é”®è¦ç‚¹ï¼š
  1. é€šè¿‡ --backend é€‰æ‹©è¿è¡Œåç«¯ï¼Œå·¥ä½œè´Ÿè½½é€»è¾‘æ— éœ€ä¿®æ”¹
     - python scheduler_comparison.py --backend sage
     - python scheduler_comparison.py --backend ray   (éœ€å®‰è£… ray_runner)

  2. ç”¨æˆ·åœ¨åˆ›å»º Environment æ—¶æŒ‡å®šè°ƒåº¦ç­–ç•¥
     - env = LocalEnvironment(scheduler="fifo")
     - env = FlownetEnvironment(scheduler=LoadAwareScheduler())

  3. å¹¶è¡Œåº¦åœ¨å®šä¹‰ transformation æ—¶æŒ‡å®š
     - .map(HeavyProcessor, parallelism=4)
     - .filter(LightFilter, parallelism=2)
    """
    )


if __name__ == "__main__":
    main()
