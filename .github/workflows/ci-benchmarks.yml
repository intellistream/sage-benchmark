# Benchmark CI for sage-benchmark
# Runs Q1-Q8 experiments against real sagellm CPU backend
#
# Pattern aligned with sagellm-benchmark CI:
#   - China mirrors for pip & HF
#   - Robust health checks with diagnostics
#   - Separate artifact upload
#
# Trigger: manual dispatch or nightly schedule
# Results flow: run benchmarks → aggregate → commit hf_data/ → upload-to-hf.yml

name: Benchmark CI

on:
  workflow_dispatch:
    inputs:
      quick:
        description: "Run in quick (reduced-scale) mode"
        required: false
        default: "true"
        type: choice
        options:
          - "true"
          - "false"
      experiments:
        description: "Experiments to run (comma-separated Q-IDs or 'all')"
        required: false
        default: "all"
  schedule:
    - cron: "0 2 * * *"

concurrency:
  group: benchmark-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-benchmarks:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    env:
      HF_ENDPOINT: https://hf-mirror.com
      SAGELLM_PORT: 8888
      SAGELLM_ENGINE_PORT: 8889
      SAGELLM_EMBED_PORT: 8890
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Configure pip mirror
        run: |
          mkdir -p ~/.pip
          cat > ~/.pip/pip.conf << 'EOF'
          [global]
          index-url = https://pypi.tuna.tsinghua.edu.cn/simple
          trusted-host = pypi.tuna.tsinghua.edu.cn
          EOF

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install "isagellm>=0.5.2.0"
          python -m pip install -e .

      - name: Start LLM engine (background)
        run: |
          sagellm serve-engine \
            --engine-kind llm \
            --backend cpu \
            --model sshleifer/tiny-gpt2 \
            --port "$SAGELLM_ENGINE_PORT" \
            > /tmp/llm-engine.log 2>&1 &
          echo "LLM_ENGINE_PID=$!" >> "$GITHUB_ENV"

      - name: Start gateway + embedding (background)
        run: |
          sagellm serve \
            --backend cpu \
            --model sshleifer/tiny-gpt2 \
            --port "$SAGELLM_PORT" \
            --with-embedding \
            --embedding-model sentence-transformers/all-MiniLM-L6-v2 \
            --embedding-port "$SAGELLM_EMBED_PORT" \
            > /tmp/sagellm.log 2>&1 &
          echo "SAGELLM_PID=$!" >> "$GITHUB_ENV"

      - name: Wait for gateway health
        run: |
          echo "Waiting for gateway on port ${SAGELLM_PORT}..."
          for i in $(seq 1 72); do
            if curl -s -o /dev/null -w '%{http_code}' "http://localhost:${SAGELLM_PORT}/health" 2>/dev/null | grep -q '200'; then
              echo "Gateway healthy after ~$((i * 5))s"
              exit 0
            fi
            sleep 5
          done
          echo "::error::Gateway not healthy after 6 min"
          echo "--- sagellm.log (last 80 lines) ---"
          tail -80 /tmp/sagellm.log
          exit 1

      - name: Wait for LLM engine and register
        run: |
          echo "Waiting for LLM engine on port ${SAGELLM_ENGINE_PORT}..."
          ENGINE_READY=0
          for i in $(seq 1 60); do
            if curl -s -o /dev/null -w '%{http_code}' "http://localhost:${SAGELLM_ENGINE_PORT}/health" 2>/dev/null | grep -q '200'; then
              echo "LLM engine healthy after ~$((i * 5))s"
              ENGINE_READY=1
              break
            fi
            sleep 5
          done
          if [ "$ENGINE_READY" -eq 0 ]; then
            echo "::error::LLM engine not healthy after 5 min"
            echo "--- llm-engine.log ---"
            cat /tmp/llm-engine.log
            exit 1
          fi
          echo "Registering LLM engine to gateway (with retries)..."
          REGISTERED=0
          for attempt in $(seq 1 12); do
            HTTP_CODE=$(curl -s -o /tmp/register-llm.json -w '%{http_code}' \
              -X POST "http://localhost:${SAGELLM_PORT}/v1/management/engines/register" \
              -H 'Content-Type: application/json' \
              -d "{\"engine_id\":\"engine-cpu-${SAGELLM_ENGINE_PORT}\",\"model_id\":\"sshleifer/tiny-gpt2\",\"host\":\"localhost\",\"port\":${SAGELLM_ENGINE_PORT},\"engine_kind\":\"llm\"}" \
              2>/dev/null || echo "000")
            echo "  Attempt $attempt: HTTP $HTTP_CODE"
            if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ] 2>/dev/null; then
              REGISTERED=1
              break
            fi
            # Check if lifecycle manager already auto-registered it
            MODELS=$(curl -s "http://localhost:${SAGELLM_PORT}/v1/models" 2>/dev/null || true)
            if echo "$MODELS" | python -c "import sys,json; d=json.load(sys.stdin); sys.exit(0 if any('tiny-gpt2' in m.get('id','') for m in d.get('data',[])) else 1)" 2>/dev/null; then
              echo "  Lifecycle manager already registered the model"
              REGISTERED=1
              break
            fi
            sleep 5
          done
          if [ "$REGISTERED" -eq 0 ]; then
            echo "::error::LLM engine registration failed after 12 attempts"
            cat /tmp/register-llm.json
            exit 1
          fi
          echo "LLM engine registered. Waiting for control plane to mark it healthy..."
          for i in $(seq 1 24); do
            MODELS=$(curl -s "http://localhost:${SAGELLM_PORT}/v1/models" 2>/dev/null || true)
            if echo "$MODELS" | python -c "import sys,json; d=json.load(sys.stdin); sys.exit(0 if any('tiny-gpt2' in m.get('id','') for m in d.get('data',[])) else 1)" 2>/dev/null; then
              echo "Model sshleifer/tiny-gpt2 visible in /v1/models after ~$((i * 5))s"
              break
            fi
            if [ "$i" -eq 24 ]; then
              echo "::warning::tiny-gpt2 not in /v1/models after 2 min; proceeding anyway"
            fi
            sleep 5
          done

      - name: Wait for embedding engine
        run: |
          echo "Waiting for embedding model registration..."
          for i in $(seq 1 36); do
            RESP=$(curl -s "http://localhost:${SAGELLM_PORT}/v1/models" 2>/dev/null || true)
            if [ -n "$RESP" ] && echo "$RESP" | python -c "import sys,json; d=json.load(sys.stdin); models=[m.get('id','') for m in d.get('data',[])]; sys.exit(0 if any('MiniLM' in m or 'embed' in m.lower() for m in models) else 1)" 2>/dev/null; then
              echo "Embedding registered after ~$((i * 5))s"
              exit 0
            fi
            sleep 5
          done
          echo "::warning::Embedding not registered after 3 min; continuing anyway"

      - name: Smoke-test LLM endpoint
        run: |
          RESP=$(curl -s -w '\n%{http_code}' -X POST "http://localhost:${SAGELLM_PORT}/v1/chat/completions" \
            -H "Content-Type: application/json" \
            -d '{"model":"sshleifer/tiny-gpt2","messages":[{"role":"user","content":"hi"}],"max_tokens":5}')
          HTTP_CODE=$(echo "$RESP" | tail -1)
          BODY=$(echo "$RESP" | sed '$d')
          echo "HTTP $HTTP_CODE"
          if [ "$HTTP_CODE" -ge 400 ] 2>/dev/null || [ -z "$BODY" ]; then
            echo "::error::LLM smoke test failed (HTTP $HTTP_CODE)"
            echo "$BODY"
            tail -40 /tmp/sagellm.log
            exit 1
          fi
          echo "$BODY" | python -c "import sys,json; d=json.load(sys.stdin); print('LLM ok: model=' + d.get('model','?'))"

      - name: Smoke-test embedding endpoint
        run: |
          RESP=$(curl -s -w '\n%{http_code}' -X POST "http://localhost:${SAGELLM_PORT}/v1/embeddings" \
            -H "Content-Type: application/json" \
            -d '{"model":"sentence-transformers/all-MiniLM-L6-v2","input":["hello"]}')
          HTTP_CODE=$(echo "$RESP" | tail -1)
          BODY=$(echo "$RESP" | sed '$d')
          echo "HTTP $HTTP_CODE"
          if [ "$HTTP_CODE" -ge 400 ] 2>/dev/null || [ -z "$BODY" ]; then
            echo "::warning::Embedding smoke test failed (HTTP $HTTP_CODE), continuing"
            echo "$BODY"
          else
            echo "$BODY" | python -c "import sys,json; d=json.load(sys.stdin); print('Embed ok, dim=' + str(len(d['data'][0]['embedding'])))"
          fi

      - name: Run Q1-Q8 benchmarks
        run: |
          QUICK_FLAG=""
          [ "${{ github.event.inputs.quick || 'true' }}" = "true" ] && QUICK_FLAG="--quick"
          EXPERIMENTS="${{ github.event.inputs.experiments || 'all' }}"
          if [ "$EXPERIMENTS" = "all" ]; then
            python __main__.py --all $QUICK_FLAG --output-dir results/ci_run
          else
            IFS=',' read -ra EXP_LIST <<< "$EXPERIMENTS"
            for EXP in "${EXP_LIST[@]}"; do
              python __main__.py --experiment "$(echo "$EXP" | tr -d ' ')" $QUICK_FLAG --output-dir results/ci_run
            done
          fi

      - name: Aggregate results
        run: python scripts/aggregate_for_hf.py

      - name: Commit and push hf_data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add hf_data/
          git diff --cached --quiet || (git commit -m "ci: benchmark results $(date -u +%Y-%m-%dT%H:%M:%SZ) [run ${{ github.run_id }}]" && git push)

      - name: Upload benchmark artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_id }}
          path: results/ci_run
          if-no-files-found: warn

      - name: Upload sagellm logs (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: sagellm-logs-${{ github.run_id }}
          path: /tmp/sagellm.log
