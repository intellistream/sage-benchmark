#!/usr/bin/env python3
"""
ç”¨æˆ·æœ¬åœ°èšåˆå‘½ä»¤ï¼šä» HF æ‹‰å–æœ€æ–°æ•°æ®å¹¶ä¸æœ¬åœ°ç»“æœåˆå¹¶

è¿™æ˜¯ç”¨æˆ·åœ¨æœ¬åœ°è¿è¡Œçš„å‘½ä»¤ï¼Œç”¨äºå‡†å¤‡ä¸Šä¼ åˆ° GitHub çš„æ•°æ®ã€‚

å·¥ä½œæµç¨‹ï¼š
1. ä» HF ä¸‹è½½å…¬å¼€çš„ benchmark æ•°æ®ï¼ˆæ— éœ€ tokenï¼‰
2. æ‰«ææœ¬åœ° results/ ç›®å½•çš„æ–°ç»“æœï¼ˆunified_results.jsonlï¼‰
3. æ™ºèƒ½åˆå¹¶ï¼ˆå»é‡ï¼Œé€‰æ€§èƒ½æ›´å¥½çš„ï¼‰
4. ä¿å­˜åˆ° hf_data/ ç›®å½•
5. ç”¨æˆ·æäº¤ hf_data/ åˆ° gitï¼ˆä¸æäº¤ results/ï¼‰

è¿è¡Œæ–¹å¼ï¼š
    python scripts/aggregate_for_hf.py

HF ä»“åº“ï¼ˆå…¬å¼€è®¿é—®ï¼‰ï¼š
    https://huggingface.co/datasets/intellistream/sage-benchmark-results
"""

from __future__ import annotations

import json
import urllib.request
from pathlib import Path

# HF é…ç½®
HF_REPO = "intellistream/sage-benchmark-results"
HF_BRANCH = "main"


def download_from_hf(filename: str) -> list[dict]:
    """ä» Hugging Face ä¸‹è½½ç°æœ‰æ•°æ®ï¼ˆå…¬å¼€ï¼Œæ— éœ€ tokenï¼‰ã€‚"""
    # ä¼˜å…ˆä½¿ç”¨ mirrorï¼Œé¿å…å›½å†…ç½‘ç»œè¶…æ—¶
    mirror = "https://hf-mirror.com"
    url = f"{mirror}/datasets/{HF_REPO}/resolve/{HF_BRANCH}/{filename}"
    print(f"ğŸ“¥ ä¸‹è½½ HF æ•°æ®: {url}")

    try:
        with urllib.request.urlopen(url, timeout=30) as response:
            data = json.loads(response.read().decode("utf-8"))
            print(f"  âœ“ ä¸‹è½½æˆåŠŸ: {len(data)} æ¡è®°å½•")
            return data
    except urllib.error.HTTPError as e:
        if e.code == 404:
            print(f"  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆé¦–æ¬¡ä¸Šä¼ ï¼‰")
        else:
            # å°è¯•ä¸»ç«™
            alt_url = f"https://huggingface.co/datasets/{HF_REPO}/resolve/{HF_BRANCH}/{filename}"
            print(f"  âš ï¸ mirror HTTP {e.code}ï¼Œå°è¯•ä¸»ç«™: {alt_url}")
            try:
                with urllib.request.urlopen(alt_url, timeout=30) as response2:
                    data = json.loads(response2.read().decode("utf-8"))
                    print(f"  âœ“ ä¸‹è½½æˆåŠŸ: {len(data)} æ¡è®°å½•")
                    return data
            except Exception as e2:
                print(f"  âš ï¸ ä¸»ç«™ä¹Ÿå¤±è´¥: {e2}")
        return []
    except Exception as e:
        print(f"  âš ï¸ ä¸‹è½½å¤±è´¥: {e}")
        return []


def load_local_results(results_dir: Path) -> list[dict]:
    """é€’å½’åŠ è½½ results/ ç›®å½•ä¸‹çš„æ‰€æœ‰ unified_results.jsonl æ–‡ä»¶ã€‚"""
    all_records: list[dict] = []

    for jsonl_file in results_dir.rglob("unified_results.jsonl"):
        try:
            with jsonl_file.open("r", encoding="utf-8") as fh:
                for line in fh:
                    stripped = line.strip()
                    if not stripped:
                        continue
                    record = json.loads(stripped)
                    all_records.append(record)
            print(f"  âœ“ åŠ è½½: {jsonl_file.relative_to(results_dir)}")
        except Exception as e:
            print(f"  âœ— åŠ è½½å¤±è´¥: {jsonl_file} - {e}")

    return all_records


def get_config_key(entry: dict) -> str:
    """ç”Ÿæˆé…ç½®å”¯ä¸€æ ‡è¯† keyï¼ˆç”¨äºå»é‡ï¼‰ã€‚"""
    parts = [
        str(entry.get("backend", "")),
        str(entry.get("workload", "")),
        str(entry.get("seed", "")),
        str(entry.get("nodes", "")),
        str(entry.get("parallelism", "")),
        str(entry.get("config_hash", "")),
    ]
    return "|".join(parts)


def is_better_result(new_entry: dict, existing_entry: dict) -> bool:
    """åˆ¤æ–­æ–°ç»“æœæ˜¯å¦æ¯”ç°æœ‰ç»“æœæ›´å¥½ï¼ˆthroughput ä¼˜å…ˆï¼Œå…¶æ¬¡ latency_p50 æ›´ä½ï¼‰ã€‚"""
    new_tp = new_entry.get("throughput")
    ext_tp = existing_entry.get("throughput")
    if new_tp is not None and ext_tp is not None:
        if abs(new_tp - ext_tp) > 1e-9:
            return new_tp > ext_tp

    new_lat = new_entry.get("latency_p50")
    ext_lat = existing_entry.get("latency_p50")
    if new_lat is not None and ext_lat is not None:
        return new_lat < ext_lat

    return False


def merge_results(existing: list[dict], new_results: list[dict]) -> list[dict]:
    """åˆå¹¶ç°æœ‰æ•°æ®å’Œæ–°æ•°æ®ï¼ˆä»¥ existing ä¸ºåŸºå‡†ï¼Œnew_results è¿½åŠ æˆ–æ›´æ–°ï¼‰ã€‚"""
    merged: dict[str, dict] = {}

    # å…ˆåŠ å…¥ç°æœ‰æ•°æ®
    for entry in existing:
        key = get_config_key(entry)
        merged[key] = entry

    added = updated = skipped = 0

    for entry in new_results:
        key = get_config_key(entry)
        if key not in merged:
            merged[key] = entry
            added += 1
            print(f"    âœ“ æ–°å¢: {key[:60]}...")
        elif is_better_result(entry, merged[key]):
            merged[key] = entry
            updated += 1
            print(f"    â†‘ æ›´æ–° (æ›´å¥½): {key[:60]}...")
        else:
            skipped += 1

    print(f"  ğŸ“Š åˆå¹¶ç»“æœ: æ–°å¢ {added}, æ›´æ–° {updated}, è·³è¿‡ {skipped}, æ€»è®¡ {len(merged)}")
    return list(merged.values())


def main() -> None:
    print("=" * 70)
    print("ğŸ“¦ SAGE Benchmark - æœ¬åœ°èšåˆå·¥å…·")
    print("=" * 70)

    base_dir = Path(__file__).parent.parent
    results_dir = base_dir / "results"
    hf_output_dir = base_dir / "hf_data"

    hf_output_dir.mkdir(exist_ok=True)

    # Step 1: ä» HF ä¸‹è½½ç°æœ‰æ•°æ®
    print(f"\nğŸ“¥ ä» Hugging Face ä¸‹è½½æœ€æ–°æ•°æ®...")
    print(f"   ä»“åº“: https://huggingface.co/datasets/{HF_REPO}")
    existing_results = download_from_hf("benchmark_results.json")

    # Step 2: åŠ è½½æœ¬åœ°æ–°ç»“æœ
    print(f"\nğŸ“‚ æ‰«ææœ¬åœ° results/ ç›®å½•...")
    if not results_dir.exists():
        print(f"  âš ï¸ results/ ç›®å½•ä¸å­˜åœ¨")
        print(f"  ğŸ’¡ è¯·å…ˆè¿è¡Œ benchmark ç”Ÿæˆç»“æœ")
        local_records: list[dict] = []
    else:
        local_records = load_local_results(results_dir)
        if not local_records:
            print(f"  âš ï¸ æœªæ‰¾åˆ°ä»»ä½• unified_results.jsonl æ–‡ä»¶")
            print(f"  ğŸ’¡ è¯·å…ˆè¿è¡Œ benchmark: python experiments/run_all.sh")
        else:
            print(f"  âœ“ æ‰¾åˆ° {len(local_records)} æ¡æœ¬åœ°ç»“æœ")

    # Step 3: æ™ºèƒ½åˆå¹¶
    print(f"\nğŸ”€ æ™ºèƒ½åˆå¹¶æ•°æ®...")
    merged = merge_results(existing_results, local_records)

    # Step 4: ä¿å­˜åˆ° hf_data/
    print(f"\nğŸ’¾ ä¿å­˜åˆ° hf_data/ ç›®å½•...")
    output_file = hf_output_dir / "benchmark_results.json"
    with output_file.open("w", encoding="utf-8") as fh:
        json.dump(merged, fh, indent=2, ensure_ascii=False)
    print(f"  âœ“ {output_file.name} ({len(merged)} æ¡)")

    print(f"\n" + "=" * 70)
    print(f"âœ… èšåˆå®Œæˆï¼")
    print(f"=" * 70)
    print(f"\nğŸ“Œ ä¸‹ä¸€æ­¥æ“ä½œï¼š")
    print(f"  1. æäº¤èšåˆæ•°æ®åˆ° git:")
    print(f"     git add hf_data/")
    print(f"     git commit -m 'feat: add benchmark results'")
    print(f"     git push")
    print(f"\n  2. GitHub Actions ä¼šè‡ªåŠ¨:")
    print(f"     - ä¸ HF æœ€æ–°æ•°æ®åˆå¹¶ï¼ˆè§£å†³å¹¶å‘å†²çªï¼‰")
    print(f"     - ä¸Šä¼ åˆ° Hugging Face")
    print(f"     - æ¸…ç† hf_data/ ä¿æŒä»“åº“è½»é‡")
    print(f"\nğŸ’¡ æç¤º: results/ ç›®å½•ä¸ä¼šè¢«æäº¤ï¼ˆåœ¨ .gitignore ä¸­ï¼‰")
    print(f"=" * 70)


if __name__ == "__main__":
    main()
