#!/usr/bin/env python3
"""
å¹¶å‘å®‰å…¨çš„åˆå¹¶è„šæœ¬ï¼ˆç”± GitHub Actions è°ƒç”¨ï¼‰

ç”¨äºåœ¨ä¸Šä¼ åˆ° HF å‰å†æ¬¡åˆå¹¶æœ€æ–°æ•°æ®ï¼Œè§£å†³å¤šç”¨æˆ·åŒæ—¶æäº¤çš„å¹¶å‘å†²çªã€‚

å·¥ä½œæµç¨‹ï¼š
1. è¯»å–ç”¨æˆ·æäº¤çš„ hf_data/ï¼ˆå¯èƒ½åŸºäºæ—§ç‰ˆæœ¬ HF æ•°æ®ï¼‰
2. ä» HF ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆå¯èƒ½å·²è¢«å…¶ä»–ç”¨æˆ·æ›´æ–°ï¼‰
3. ä¸‰æ–¹æ™ºèƒ½åˆå¹¶ï¼ˆä»¥ HF æœ€æ–°ç‰ˆæœ¬ä¸ºæƒå¨åŸºå‡†ï¼‰
4. ä¿å­˜åˆå¹¶ç»“æœï¼ˆä¾› upload_to_hf.py ä½¿ç”¨ï¼‰
"""

from __future__ import annotations

import json
import urllib.request
from pathlib import Path

# HF é…ç½®
HF_REPO = "intellistream/sage-benchmark-results"
HF_BRANCH = "main"


def download_from_hf(filename: str) -> list[dict]:
    """ä» HF ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆå…¬å¼€ï¼Œæ— éœ€ tokenï¼‰ã€‚"""
    mirror = "https://hf-mirror.com"
    url = f"{mirror}/datasets/{HF_REPO}/resolve/{HF_BRANCH}/{filename}"
    print(f"  ğŸ“¥ {url}")

    try:
        with urllib.request.urlopen(url, timeout=30) as response:
            data = json.loads(response.read().decode("utf-8"))
            print(f"    âœ“ {len(data)} æ¡è®°å½•")
            return data
    except urllib.error.HTTPError as e:
        if e.code == 404:
            print("    âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆé¦–æ¬¡ä¸Šä¼ ï¼‰")
        else:
            # å›é€€åˆ°ä¸»ç«™
            alt = f"https://huggingface.co/datasets/{HF_REPO}/resolve/{HF_BRANCH}/{filename}"
            try:
                with urllib.request.urlopen(alt, timeout=30) as r2:
                    data = json.loads(r2.read().decode("utf-8"))
                    print(f"    âœ“ {len(data)} æ¡è®°å½•ï¼ˆä¸»ç«™ï¼‰")
                    return data
            except Exception as e2:
                print(f"    âš ï¸ ä¸»ç«™å¤±è´¥: {e2}")
        return []
    except Exception as e:
        print(f"    âš ï¸ ä¸‹è½½å¤±è´¥: {e}")
        return []


def get_config_key(entry: dict) -> str:
    """ç”Ÿæˆé…ç½®å”¯ä¸€æ ‡è¯† keyã€‚"""
    parts = [
        str(entry.get("backend", "")),
        str(entry.get("workload", "")),
        str(entry.get("seed", "")),
        str(entry.get("nodes", "")),
        str(entry.get("parallelism", "")),
        str(entry.get("config_hash", "")),
    ]
    return "|".join(parts)


def is_better_result(new_entry: dict, existing_entry: dict) -> bool:
    """åˆ¤æ–­æ–°ç»“æœæ˜¯å¦ä¼˜äºç°æœ‰ç»“æœã€‚"""
    new_tp = new_entry.get("throughput")
    ext_tp = existing_entry.get("throughput")
    if new_tp is not None and ext_tp is not None:
        if abs(new_tp - ext_tp) > 1e-9:
            return new_tp > ext_tp

    new_lat = new_entry.get("latency_p50")
    ext_lat = existing_entry.get("latency_p50")
    if new_lat is not None and ext_lat is not None:
        return new_lat < ext_lat

    return False


def smart_merge(hf_latest: list[dict], user_data: list[dict]) -> list[dict]:
    """ä¸‰æ–¹æ™ºèƒ½åˆå¹¶ã€‚

    å…³é”®è§„åˆ™ï¼š
    1. HF æœ€æ–°æ•°æ®ä¸ºåŸºå‡†ï¼ˆæƒå¨ç‰ˆæœ¬ï¼‰
    2. ç”¨æˆ·æ•°æ®è¿½åŠ æˆ–æ›´æ–°
    3. ç›¸åŒé…ç½®æ—¶ï¼Œé€‰æ‹©æ€§èƒ½æ›´å¥½çš„
    4. ä¸åŒé…ç½®åˆ™è¿½åŠ 

    è¿™æ ·å³ä½¿ç”¨æˆ·åŸºäºæ—§ç‰ˆæœ¬ HF æ•°æ®åˆå¹¶ï¼Œä¹Ÿèƒ½ä¸æœ€æ–°ç‰ˆæœ¬æ­£ç¡®åˆå¹¶ã€‚
    """
    merged: dict[str, dict] = {}

    # å…ˆåŠ å…¥ HF æœ€æ–°æ•°æ®ï¼ˆæƒå¨ç‰ˆæœ¬ï¼‰
    for entry in hf_latest:
        key = get_config_key(entry)
        merged[key] = entry

    added = updated = skipped = 0

    # åˆå¹¶ç”¨æˆ·æ•°æ®
    for entry in user_data:
        key = get_config_key(entry)
        if key not in merged:
            merged[key] = entry
            added += 1
            print(f"    âœ“ æ–°å¢: {key[:60]}...")
        elif is_better_result(entry, merged[key]):
            merged[key] = entry
            updated += 1
            print(f"    â†‘ æ›´æ–° (æ›´å¥½): {key[:60]}...")
        else:
            skipped += 1
            print(f"    â—‹ è·³è¿‡ (å·²æœ‰æ›´å¥½): {key[:60]}...")

    print(f"  ğŸ“Š åˆå¹¶ç»“æœ: æ–°å¢ {added}, æ›´æ–° {updated}, è·³è¿‡ {skipped}, æ€»è®¡ {len(merged)}")
    return list(merged.values())


def main() -> None:
    print("=" * 60)
    print("ğŸ”€ å¹¶å‘å®‰å…¨åˆå¹¶ï¼ˆGitHub Actionsï¼‰")
    print("=" * 60)

    hf_data_dir = Path("hf_data")

    if not hf_data_dir.exists():
        print("\nâŒ hf_data/ ç›®å½•ä¸å­˜åœ¨")
        print("ğŸ’¡ ç”¨æˆ·åº”è¯¥å…ˆè¿è¡Œ 'python scripts/aggregate_for_hf.py'")
        raise SystemExit(1)

    # 1. è¯»å–ç”¨æˆ·æäº¤çš„æ•°æ®
    print("\nğŸ“‚ è¯»å–ç”¨æˆ·æäº¤çš„æ•°æ®...")
    user_file = hf_data_dir / "benchmark_results.json"

    if not user_file.exists():
        print(f"  âš ï¸ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {user_file}")
        raise SystemExit(1)

    user_data: list[dict] = json.loads(user_file.read_text(encoding="utf-8"))
    print(f"  âœ“ {len(user_data)} æ¡")

    # 2. ä» HF ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆå¯èƒ½å·²è¢«å…¶ä»–ç”¨æˆ·æ›´æ–°ï¼‰
    print("\nğŸ“¥ ä» Hugging Face ä¸‹è½½æœ€æ–°æ•°æ®...")
    hf_latest = download_from_hf("benchmark_results.json")

    # 3. æ™ºèƒ½åˆå¹¶
    print("\nğŸ”€ æ™ºèƒ½åˆå¹¶ï¼ˆè§£å†³å¹¶å‘å†²çªï¼‰...")
    merged = smart_merge(hf_latest, user_data)

    # 4. ä¿å­˜åˆå¹¶ç»“æœï¼ˆè¦†ç›–ç”¨æˆ·æäº¤çš„ç‰ˆæœ¬ï¼Œä¾› upload_to_hf.py ä½¿ç”¨ï¼‰
    print("\nğŸ’¾ ä¿å­˜åˆå¹¶ç»“æœ...")
    user_file.write_text(
        json.dumps(merged, indent=2, ensure_ascii=False),
        encoding="utf-8",
    )
    print(f"  âœ“ {user_file} ({len(merged)} æ¡)")

    print("\nâœ… å¹¶å‘å®‰å…¨åˆå¹¶å®Œæˆï¼")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥: è¿è¡Œ upload_to_hf.py ä¸Šä¼ åˆ° Hugging Face")


if __name__ == "__main__":
    main()
