experiment:
  name: "q1_pipelinechain"
  description: "Q1 PipelineChain (e2e_pipeline): End-to-end RAG pipeline workload family"
  section: "Q1"

hardware:
  gpus: 2
  gpu_type: "A100"
  cpu_cores: 64
  memory_gb: 256

models:
  llm:
    name: "Qwen/Qwen2.5-0.5B-Instruct"
    instances: 2
    device: "cuda"
    tensor_parallel: 1
  embedding:
    name: "BAAI/bge-small-zh-v1.5"
    instances: 1
    device: "cpu"

workload:
  total_requests: 1000
  warmup_requests: 100
  llm_ratio: 0.6
  request_rate: 40.0
  input_tokens:
    min: 256
    max: 512
  output_tokens:
    min: 64
    max: 256
  seed: 42

metrics:
  latency_percentiles: [50, 95, 99]
  slo_targets:
    chat_p99_ms: 500
    embedding_p99_ms: 100
  report_interval_s: 10

output:
  results_dir: "results/q1"
  save_raw_data: true
  generate_plots: true
  export_latex: true
