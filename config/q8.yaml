experiment:
  name: "q8_recoverysoak"
  description: "Q8 RecoverySoak (recovery): Fault-recovery soak workload family"
  section: "Q8"

hardware:
  gpus: 2
  gpu_type: "A100"
  cpu_cores: 64
  memory_gb: 256

models:
  llm:
    name: "Qwen/Qwen2.5-7B-Instruct"
    instances: 2
    device: "cuda"
    tensor_parallel: 1
  embedding:
    name: "BAAI/bge-m3"
    instances: 1
    device: "cpu"

workload:
  total_requests: 1200
  warmup_requests: 100
  llm_ratio: 0.7
  request_rate: 65.0
  input_tokens:
    min: 256
    max: 512
  output_tokens:
    min: 64
    max: 256
  seed: 42

metrics:
  latency_percentiles: [50, 95, 99]
  slo_targets:
    chat_p99_ms: 700
    embedding_p99_ms: 130
  report_interval_s: 10

output:
  results_dir: "results/q8"
  save_raw_data: true
  generate_plots: true
  export_latex: true
