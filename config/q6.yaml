experiment:
  name: "q6_bursttown"
  description: "Q6 BurstTown (burst_priority): Bursty mixed-priority transactional workload family"
  section: "Q6"

hardware:
  gpus: 2
  gpu_type: "A100"
  cpu_cores: 64
  memory_gb: 256

models:
  llm:
    name: "Qwen/Qwen2.5-7B-Instruct"
    instances: 2
    device: "cuda"
    tensor_parallel: 1
  embedding:
    name: "BAAI/bge-m3"
    instances: 1
    device: "cpu"

workload:
  total_requests: 1400
  warmup_requests: 80
  llm_ratio: 0.75
  request_rate: 90.0
  input_tokens:
    min: 128
    max: 512
  output_tokens:
    min: 64
    max: 256
  seed: 42

metrics:
  latency_percentiles: [50, 95, 99]
  slo_targets:
    chat_p99_ms: 650
    embedding_p99_ms: 120
  report_interval_s: 5

output:
  results_dir: "results/q6"
  save_raw_data: true
  generate_plots: true
  export_latex: true
